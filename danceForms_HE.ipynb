{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "danceForms_HE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjit1995/IdentifyDanceForms_HackerEarth/blob/master/danceForms_HE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "KUu4vOt5zI9d",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CxmDMK4yupqg"
      },
      "source": [
        "# Object detection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfBg1C5NB3X0"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/object_detection\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sy553YSVmYiK"
      },
      "source": [
        "This Colab demonstrates use of a TF-Hub module trained to perform object detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v4XGxDrCkeip"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "6cPY9Ou4sWs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8b9f53df-c33a-4121-becd-35d28ad20911"
      },
      "source": [
        "#@title Imports and function definitions\n",
        "\n",
        "# For running inference on the TF-Hub module.\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# For downloading the image.\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps\n",
        "\n",
        "# For measuring the inference time.\n",
        "import time\n",
        "\n",
        "# Print Tensorflow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Check available GPU devices.\n",
        "print(\"The following GPU devices are available: %s\" % tf.test.gpu_device_name())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "The following GPU devices are available: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZGkrXGy62409"
      },
      "source": [
        "## Example use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vlA3CftFpRiW"
      },
      "source": [
        "### Helper functions for downloading images and for visualization.\n",
        "\n",
        "Visualization code adapted from [TF object detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py) for the simplest required functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D9IwDpOtpIHW",
        "colab": {}
      },
      "source": [
        "def display_image(image):\n",
        "  fig = plt.figure(figsize=(20, 15))\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image)\n",
        "\n",
        "\n",
        "def download_and_resize_image(url, new_width=256, new_height=256,\n",
        "                              display=False):\n",
        "  _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "  response = urlopen(url)\n",
        "  image_data = response.read()\n",
        "  image_data = BytesIO(image_data)\n",
        "  pil_image = Image.open(image_data)\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "  pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "  pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "  print(\"Image downloaded to %s.\" % filename)\n",
        "  if display:\n",
        "    display_image(pil_image)\n",
        "  return filename\n",
        "\n",
        "\n",
        "def draw_bounding_box_on_image(image,\n",
        "                               ymin,\n",
        "                               xmin,\n",
        "                               ymax,\n",
        "                               xmax,\n",
        "                               color,\n",
        "                               font,\n",
        "                               thickness=4,\n",
        "                               display_str_list=()):\n",
        "  \"\"\"Adds a bounding box to an image.\"\"\"\n",
        "  draw = ImageDraw.Draw(image)\n",
        "  im_width, im_height = image.size\n",
        "  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
        "                                ymin * im_height, ymax * im_height)\n",
        "  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
        "             (left, top)],\n",
        "            width=thickness,\n",
        "            fill=color)\n",
        "\n",
        "  # If the total height of the display strings added to the top of the bounding\n",
        "  # box exceeds the top of the image, stack the strings below the bounding box\n",
        "  # instead of above.\n",
        "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
        "  # Each display_str has a top and bottom margin of 0.05x.\n",
        "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
        "\n",
        "  if top > total_display_str_height:\n",
        "    text_bottom = top\n",
        "  else:\n",
        "    text_bottom = top + total_display_str_height\n",
        "  # Reverse list and print from bottom to top.\n",
        "  for display_str in display_str_list[::-1]:\n",
        "    text_width, text_height = font.getsize(display_str)\n",
        "    margin = np.ceil(0.05 * text_height)\n",
        "    draw.rectangle([(left, text_bottom - text_height - 2 * margin),\n",
        "                    (left + text_width, text_bottom)],\n",
        "                   fill=color)\n",
        "    draw.text((left + margin, text_bottom - text_height - margin),\n",
        "              display_str,\n",
        "              fill=\"black\",\n",
        "              font=font)\n",
        "    text_bottom -= text_height - 2 * margin\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import display\n",
        "\n",
        "def draw_boxes(image, boxes, class_names, scores, max_boxes, img_num, min_score=0.2):\n",
        "  \"\"\"Overlay labeled boxes on an image with formatted scores and label names.\"\"\"\n",
        "  colors = list(ImageColor.colormap.values())\n",
        "\n",
        "  try:\n",
        "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\",\n",
        "                              25)\n",
        "  except IOError:\n",
        "    print(\"Font not found, using default font.\")\n",
        "    font = ImageFont.load_default()\n",
        "  \n",
        "  print(len(boxes))\n",
        "\n",
        "  start_num = img_num\n",
        "  for i in range(min(boxes.shape[0], max_boxes)):\n",
        "    if scores[i] >= min_score:\n",
        "      ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
        "      display_str = \"{}: {}%\".format(class_names[i].decode(\"ascii\"),\n",
        "                                     int(100 * scores[i]))\n",
        "      color = colors[hash(class_names[i]) % len(colors)]\n",
        "      image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
        "      (frame_height, frame_width) = image.shape[:2]\n",
        "      #print(np.squeeze(boxes))\n",
        "      #print(boxes[i][0]*frame_height)\n",
        "      y_min = int(boxes[i][0]*frame_height)\n",
        "      x_min = int(boxes[i][1]*frame_width)\n",
        "      y_max = int(boxes[i][2]*frame_height) \n",
        "      x_max = int(boxes[i][3]*frame_width)\n",
        "      #print(y_max, y_min, x_max, x_min)\n",
        "      #cropped_img = image[y_max:y_min,x_max:x_min]\n",
        "      cropped_img = image_pil.crop((x_min, y_min, x_max, y_max))\n",
        "      #print(image.shape)\n",
        "      #print(cropped_img)\n",
        "      #display(cropped_img)\n",
        "      cropped_img.save(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/test/cropped/\" + str(img_num) + \".jpg\")\n",
        "      img_num += 1\n",
        "      #cv2.imwrite('cropped image_' + str(i) + '.jpg', cropped_img)\n",
        "      #draw_bounding_box_on_image(image_pil,ymin,xmin,ymax,xmax,color,font,display_str_list=[display_str])\n",
        "      #np.copyto(image, np.array(image_pil))\n",
        "    \n",
        "  if start_num == img_num:\n",
        "    ymin, xmin, ymax, xmax = tuple(boxes[0])\n",
        "    display_str = \"{}: {}%\".format(class_names[0].decode(\"ascii\"),\n",
        "                                     int(100 * scores[0]))\n",
        "    color = colors[hash(class_names[0]) % len(colors)]\n",
        "    image_pil = Image.fromarray(np.uint8(image)).convert(\"RGB\")\n",
        "    (frame_height, frame_width) = image.shape[:2]\n",
        "    #print(np.squeeze(boxes))\n",
        "    #print(boxes[i][0]*frame_height)\n",
        "    y_min = int(boxes[i][0]*frame_height)\n",
        "    x_min = int(boxes[i][1]*frame_width)\n",
        "    y_max = int(boxes[i][2]*frame_height) \n",
        "    x_max = int(boxes[i][3]*frame_width)\n",
        "    #print(y_max, y_min, x_max, x_min)\n",
        "    #cropped_img = image[y_max:y_min,x_max:x_min]\n",
        "    cropped_img = image_pil.crop((x_min, y_min, x_max, y_max))\n",
        "    #print(image.shape)\n",
        "    #print(cropped_img)\n",
        "    #display(cropped_img)\n",
        "    cropped_img.save(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/test/cropped/\" + str(img_num) + \".jpg\")\n",
        "    img_num += 1\n",
        "\n",
        "  return img_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D19UCu9Q2-_8"
      },
      "source": [
        "## Apply module\n",
        "\n",
        "Load a public image from Open Images v4, save locally, and display."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "YLWNhjUY1mhg",
        "colab": {}
      },
      "source": [
        "# By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg\"  #@param\n",
        "downloaded_image_path = download_and_resize_image(image_url, 1280, 856, True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t-VdfLbC1w51"
      },
      "source": [
        "Pick an object detection module and apply on the downloaded image. Modules:\n",
        "* **FasterRCNN+InceptionResNet V2**: high accuracy,\n",
        "* **ssd+mobilenet V2**: small and fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uazJ5ASc2_QE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0246403d-8731-4cda-d700-c604f51f6feb"
      },
      "source": [
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\" #@param [\"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\", \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"]\n",
        "\n",
        "detector = hub.load(module_handle).signatures['default']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "znW8Fq1EC0x7",
        "colab": {}
      },
      "source": [
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kwGJV96WWBLH",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def run_detector(detector, path, img_num):\n",
        "  img = load_img(path)\n",
        "\n",
        "  converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  start_time = time.time()\n",
        "  result = detector(converted_img)\n",
        "  end_time = time.time()\n",
        "\n",
        "  result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "  print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "  print(\"Inference time: \", end_time-start_time)\n",
        "\n",
        "  #print(result['detection_class_entities'].type())\n",
        "  #print(result[\"detection_class_entities\"])\n",
        "  print(len(result[\"detection_scores\"]), len(result[\"detection_class_entities\"]))\n",
        "  \n",
        "  detected_classes = result[\"detection_class_entities\"].copy()\n",
        "  detected_classes = detected_classes[detected_classes == bytes(\"Person\", 'utf-8')]\n",
        "  \n",
        "  detected_scores = result[\"detection_scores\"].copy()\n",
        "  detected_scores = detected_scores[result[\"detection_class_entities\"] == bytes(\"Person\", 'utf-8')]\n",
        "  \n",
        "  detected_boxes = result[\"detection_boxes\"].copy()\n",
        "  detected_boxes = detected_boxes[result[\"detection_class_entities\"] == bytes(\"Person\", 'utf-8')]\n",
        "  \n",
        "  detected_scores_temp = detected_scores.copy()\n",
        "  detected_scores_temp = detected_scores_temp[detected_scores > 0.2]\n",
        "  #print(detected_scores)\n",
        "  \n",
        "  detected_classes_temp = detected_classes.copy()\n",
        "  detected_classes_temp = detected_classes_temp[detected_scores > 0.2]\n",
        "  #print(detected_classes)\n",
        "  \n",
        "  detected_boxes_temp = detected_boxes.copy()\n",
        "  detected_boxes_temp = detected_boxes_temp[detected_scores > 0.2]\n",
        "  #print(detected_boxes)\n",
        "  #print(result[\"detection_class_entities\"])\n",
        "  #print(result[\"detection_scores\"])\n",
        "  #print(len(detected_classes))\n",
        "  return draw_boxes(\n",
        "      img.numpy(), detected_boxes,\n",
        "      detected_classes, detected_scores, max_boxes=len(detected_classes), img_num=img_num)\n",
        "\n",
        "  #display_image(image_with_boxes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojrApQUx7FPJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_detector(detector, '/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/136.jpg', 810)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kim6zJZzr843",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "temp_train_labels = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/test.csv\")\n",
        "#print(train_labels.loc[train_labels['Image'] == \"96.jpg\"])\n",
        "count=0\n",
        "#train_labels = pd.DataFrame(columns=['Image','target','parent_image'])\n",
        "test_labels = pd.DataFrame(columns=['Image','parent_image'])\n",
        "#print(train_labels)\n",
        "for filename in os.listdir(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/test/\"):\n",
        "  if \".jpg\" in filename:\n",
        "    print(filename)\n",
        "    newCount = run_detector(detector, '/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/test/' + filename, count)\n",
        "    for i in range(count, newCount):\n",
        "      #train_labels.loc[i] = [str(i) + \".jpg\", temp_train_labels.loc[temp_train_labels.Image == str(filename),\"target\"].values[0], str(filename)]\n",
        "      test_labels.loc[i] = [str(i) + \".jpg\", str(filename)]\n",
        "    count = newCount\n",
        "    print(\"Total files created = \" + str(newCount))  \n",
        "  else:\n",
        "    continue\n",
        "#train_labels.to_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/new_train.csv\")\n",
        "test_labels.to_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/new_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjdhjAtBvXLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_test_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjmoUdtt-mYx",
        "colab_type": "code",
        "outputId": "c6c2ae7c-6aaa-4a59-e768-ea3d8e35448d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "train_labels = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/new_train.csv\")\n",
        "del train_labels['Unnamed: 0']\n",
        "sample_t = train_labels.drop(['Image'], axis=1)\n",
        "print(train_labels.parent_image.nunique())\n",
        "temp_train_labels = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train.csv\")\n",
        "print(temp_train_labels.Image.nunique())\n",
        "idx1 = pd.Index(train_labels.parent_image)\n",
        "idx2 = pd.Index(temp_train_labels.Image)\n",
        "\n",
        "idx1.difference(idx2).values\n",
        "#sample_t.drop_duplicates()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "349\n",
            "364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6lOCPT1wQUA",
        "colab_type": "code",
        "outputId": "931bb4ec-80c9-40cb-a439-3a0428c81640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_labels.parent_image.nunique())\n",
        "print(temp_train_labels.Image.nunique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "364\n",
            "364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3PQlp3156pb",
        "colab_type": "code",
        "outputId": "f2ecfdab-80e1-4b13-f832-2e3ae06d4a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "train_labels['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kathakali        106\n",
              "odissi            98\n",
              "manipuri          82\n",
              "kuchipudi         79\n",
              "bharatanatyam     76\n",
              "mohiniyattam      71\n",
              "sattriya          68\n",
              "kathak            66\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDpUJ9Rx7V4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread('/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/cropped/1388.jpg',0)\n",
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fwPbYLLuoyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_train_labels[~temp_train_labels.Image.isin(train_labels.parent_image)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgAd-jRnGG5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#temp_train_labels[temp_train_labels['Image'] == \"228.jpg\"]\n",
        "temp_train_labels.loc[temp_train_labels.Image == \"134.jpg\",\"target\"].values[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-iArnf_b1fi",
        "colab_type": "text"
      },
      "source": [
        "Augment the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z8wlyICb3Sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "def augmentData(img_file, noOfNewFiles, saveDir, imageName):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    img = load_img(img_file)\n",
        "    x = img_to_array(img)\n",
        "    x = x.reshape((1,) + x.shape)\n",
        "\n",
        "    if not os.path.exists(saveDir):\n",
        "      os.makedirs(saveDir)\n",
        "\n",
        "    i = 0\n",
        "    for batch in datagen.flow(x, batch_size=1, save_to_dir=saveDir, save_prefix=imageName, save_format='jpg'):\n",
        "        i += 1\n",
        "        if i >= noOfNewFiles:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epQ2pIPZi_Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = 0\n",
        "import cv2\n",
        "for filename in train_labels['Image']:\n",
        "  print(filename)\n",
        "  img = \"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/cropped/\" + str(filename)\n",
        "  saveDir = \"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/augmented/\" + str(count)\n",
        "  augmentData(img, 10, saveDir, count)\n",
        "  count += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWQnwtwjxYgC",
        "colab_type": "text"
      },
      "source": [
        "Start here for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KQk4O6DxWf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_labels = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/new_test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey_exl5TrGGO",
        "colab_type": "text"
      },
      "source": [
        "resizing and storing test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxL6xXn5q2b8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "all_test_images = []\n",
        "for filename in test_labels['Image']:\n",
        "  #print(filename)\n",
        "  img = cv2.imread(os.path.join(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/test/cropped/\", filename), 0)\n",
        "  #cv2_imshow(img)\n",
        "  img = cv2.resize(img, (28, 28))\n",
        "  if img is not None:\n",
        "    all_test_images.append(img)\n",
        "  print(\"Data loaded for \" + str(filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2ttWoviw7dF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_test_images = np.array(all_test_images)\n",
        "all_test_images = all_test_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RYD2SttxQMQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_test_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBa_DGv0xTM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = all_test_images.reshape(len(all_test_images), 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCuNRNXbxpom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6TTGFcswBuC",
        "colab_type": "text"
      },
      "source": [
        "Start from here for Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOJZk1gEjVR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "train_labels = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/new_train.csv\")\n",
        "train_labels = train_labels.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cr0mp9MuBYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA9wxyT5Rtt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_final = train_labels['target']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "categorical_train_labels = label_encoder.fit_transform(train_labels_final)\n",
        "le = LabelEncoder()\n",
        "le.fit(train_labels['target'])\n",
        "y_mapping = dict(zip(le.classes_, le.transform(le.classes_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aSq6mvrlKUs",
        "colab_type": "text"
      },
      "source": [
        "Load the augmented data into empty lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VixNb2yjlIAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6066ec9-147d-404c-d7c3-f4c1a159ee37"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "augmented_train_images = []\n",
        "augmented_train_labels = []\n",
        "k = 0\n",
        "for folder in os.listdir(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/augmented\"):\n",
        "  for filename in os.listdir(os.path.join(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/augmented/\") + str(folder)):\n",
        "      #print(filename)\n",
        "      img = cv2.imread(os.path.join(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/augmented/\" + str(folder), filename), 0)\n",
        "      #cv2_imshow(img)\n",
        "      img = cv2.resize(img, (28, 28))\n",
        "      if img is not None:\n",
        "        augmented_train_images.append(img)\n",
        "        #print(train_labels[k])\n",
        "        augmented_train_labels.append(categorical_train_labels[k])\n",
        "  print(\"Data loaded for \" + str(folder))\n",
        "  k += 1\n",
        "  if not os.path.exists(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/augmented/{}\".format(k)):\n",
        "        break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data loaded for 0\n",
            "Data loaded for 1\n",
            "Data loaded for 2\n",
            "Data loaded for 3\n",
            "Data loaded for 4\n",
            "Data loaded for 5\n",
            "Data loaded for 6\n",
            "Data loaded for 7\n",
            "Data loaded for 8\n",
            "Data loaded for 9\n",
            "Data loaded for 10\n",
            "Data loaded for 11\n",
            "Data loaded for 12\n",
            "Data loaded for 13\n",
            "Data loaded for 14\n",
            "Data loaded for 15\n",
            "Data loaded for 16\n",
            "Data loaded for 17\n",
            "Data loaded for 18\n",
            "Data loaded for 19\n",
            "Data loaded for 20\n",
            "Data loaded for 21\n",
            "Data loaded for 22\n",
            "Data loaded for 23\n",
            "Data loaded for 24\n",
            "Data loaded for 25\n",
            "Data loaded for 26\n",
            "Data loaded for 27\n",
            "Data loaded for 28\n",
            "Data loaded for 29\n",
            "Data loaded for 30\n",
            "Data loaded for 31\n",
            "Data loaded for 32\n",
            "Data loaded for 33\n",
            "Data loaded for 34\n",
            "Data loaded for 35\n",
            "Data loaded for 36\n",
            "Data loaded for 37\n",
            "Data loaded for 38\n",
            "Data loaded for 39\n",
            "Data loaded for 40\n",
            "Data loaded for 41\n",
            "Data loaded for 42\n",
            "Data loaded for 43\n",
            "Data loaded for 44\n",
            "Data loaded for 45\n",
            "Data loaded for 46\n",
            "Data loaded for 47\n",
            "Data loaded for 48\n",
            "Data loaded for 49\n",
            "Data loaded for 50\n",
            "Data loaded for 51\n",
            "Data loaded for 52\n",
            "Data loaded for 53\n",
            "Data loaded for 54\n",
            "Data loaded for 55\n",
            "Data loaded for 56\n",
            "Data loaded for 57\n",
            "Data loaded for 58\n",
            "Data loaded for 59\n",
            "Data loaded for 60\n",
            "Data loaded for 61\n",
            "Data loaded for 62\n",
            "Data loaded for 63\n",
            "Data loaded for 64\n",
            "Data loaded for 65\n",
            "Data loaded for 66\n",
            "Data loaded for 67\n",
            "Data loaded for 68\n",
            "Data loaded for 69\n",
            "Data loaded for 70\n",
            "Data loaded for 71\n",
            "Data loaded for 72\n",
            "Data loaded for 73\n",
            "Data loaded for 74\n",
            "Data loaded for 75\n",
            "Data loaded for 76\n",
            "Data loaded for 77\n",
            "Data loaded for 78\n",
            "Data loaded for 79\n",
            "Data loaded for 80\n",
            "Data loaded for 81\n",
            "Data loaded for 82\n",
            "Data loaded for 83\n",
            "Data loaded for 84\n",
            "Data loaded for 85\n",
            "Data loaded for 86\n",
            "Data loaded for 87\n",
            "Data loaded for 88\n",
            "Data loaded for 89\n",
            "Data loaded for 90\n",
            "Data loaded for 91\n",
            "Data loaded for 92\n",
            "Data loaded for 93\n",
            "Data loaded for 94\n",
            "Data loaded for 95\n",
            "Data loaded for 96\n",
            "Data loaded for 97\n",
            "Data loaded for 98\n",
            "Data loaded for 99\n",
            "Data loaded for 100\n",
            "Data loaded for 101\n",
            "Data loaded for 102\n",
            "Data loaded for 103\n",
            "Data loaded for 104\n",
            "Data loaded for 105\n",
            "Data loaded for 106\n",
            "Data loaded for 107\n",
            "Data loaded for 108\n",
            "Data loaded for 109\n",
            "Data loaded for 110\n",
            "Data loaded for 111\n",
            "Data loaded for 112\n",
            "Data loaded for 113\n",
            "Data loaded for 114\n",
            "Data loaded for 115\n",
            "Data loaded for 116\n",
            "Data loaded for 117\n",
            "Data loaded for 118\n",
            "Data loaded for 119\n",
            "Data loaded for 120\n",
            "Data loaded for 121\n",
            "Data loaded for 122\n",
            "Data loaded for 123\n",
            "Data loaded for 124\n",
            "Data loaded for 125\n",
            "Data loaded for 126\n",
            "Data loaded for 127\n",
            "Data loaded for 128\n",
            "Data loaded for 129\n",
            "Data loaded for 130\n",
            "Data loaded for 131\n",
            "Data loaded for 132\n",
            "Data loaded for 133\n",
            "Data loaded for 134\n",
            "Data loaded for 135\n",
            "Data loaded for 136\n",
            "Data loaded for 137\n",
            "Data loaded for 138\n",
            "Data loaded for 139\n",
            "Data loaded for 140\n",
            "Data loaded for 141\n",
            "Data loaded for 142\n",
            "Data loaded for 143\n",
            "Data loaded for 144\n",
            "Data loaded for 145\n",
            "Data loaded for 146\n",
            "Data loaded for 147\n",
            "Data loaded for 148\n",
            "Data loaded for 149\n",
            "Data loaded for 150\n",
            "Data loaded for 151\n",
            "Data loaded for 152\n",
            "Data loaded for 153\n",
            "Data loaded for 154\n",
            "Data loaded for 155\n",
            "Data loaded for 156\n",
            "Data loaded for 157\n",
            "Data loaded for 158\n",
            "Data loaded for 159\n",
            "Data loaded for 160\n",
            "Data loaded for 161\n",
            "Data loaded for 162\n",
            "Data loaded for 163\n",
            "Data loaded for 164\n",
            "Data loaded for 165\n",
            "Data loaded for 166\n",
            "Data loaded for 167\n",
            "Data loaded for 168\n",
            "Data loaded for 169\n",
            "Data loaded for 170\n",
            "Data loaded for 171\n",
            "Data loaded for 172\n",
            "Data loaded for 173\n",
            "Data loaded for 174\n",
            "Data loaded for 175\n",
            "Data loaded for 176\n",
            "Data loaded for 177\n",
            "Data loaded for 178\n",
            "Data loaded for 179\n",
            "Data loaded for 180\n",
            "Data loaded for 181\n",
            "Data loaded for 182\n",
            "Data loaded for 183\n",
            "Data loaded for 184\n",
            "Data loaded for 185\n",
            "Data loaded for 186\n",
            "Data loaded for 187\n",
            "Data loaded for 188\n",
            "Data loaded for 189\n",
            "Data loaded for 190\n",
            "Data loaded for 191\n",
            "Data loaded for 192\n",
            "Data loaded for 193\n",
            "Data loaded for 194\n",
            "Data loaded for 195\n",
            "Data loaded for 196\n",
            "Data loaded for 197\n",
            "Data loaded for 198\n",
            "Data loaded for 199\n",
            "Data loaded for 200\n",
            "Data loaded for 201\n",
            "Data loaded for 202\n",
            "Data loaded for 203\n",
            "Data loaded for 204\n",
            "Data loaded for 205\n",
            "Data loaded for 206\n",
            "Data loaded for 207\n",
            "Data loaded for 208\n",
            "Data loaded for 209\n",
            "Data loaded for 210\n",
            "Data loaded for 211\n",
            "Data loaded for 212\n",
            "Data loaded for 213\n",
            "Data loaded for 214\n",
            "Data loaded for 215\n",
            "Data loaded for 216\n",
            "Data loaded for 217\n",
            "Data loaded for 218\n",
            "Data loaded for 219\n",
            "Data loaded for 220\n",
            "Data loaded for 221\n",
            "Data loaded for 222\n",
            "Data loaded for 223\n",
            "Data loaded for 224\n",
            "Data loaded for 225\n",
            "Data loaded for 226\n",
            "Data loaded for 227\n",
            "Data loaded for 228\n",
            "Data loaded for 229\n",
            "Data loaded for 230\n",
            "Data loaded for 231\n",
            "Data loaded for 232\n",
            "Data loaded for 233\n",
            "Data loaded for 234\n",
            "Data loaded for 235\n",
            "Data loaded for 236\n",
            "Data loaded for 237\n",
            "Data loaded for 238\n",
            "Data loaded for 239\n",
            "Data loaded for 240\n",
            "Data loaded for 241\n",
            "Data loaded for 242\n",
            "Data loaded for 243\n",
            "Data loaded for 244\n",
            "Data loaded for 245\n",
            "Data loaded for 246\n",
            "Data loaded for 247\n",
            "Data loaded for 248\n",
            "Data loaded for 249\n",
            "Data loaded for 250\n",
            "Data loaded for 251\n",
            "Data loaded for 252\n",
            "Data loaded for 253\n",
            "Data loaded for 254\n",
            "Data loaded for 255\n",
            "Data loaded for 256\n",
            "Data loaded for 257\n",
            "Data loaded for 258\n",
            "Data loaded for 259\n",
            "Data loaded for 260\n",
            "Data loaded for 261\n",
            "Data loaded for 262\n",
            "Data loaded for 263\n",
            "Data loaded for 264\n",
            "Data loaded for 265\n",
            "Data loaded for 266\n",
            "Data loaded for 267\n",
            "Data loaded for 268\n",
            "Data loaded for 269\n",
            "Data loaded for 270\n",
            "Data loaded for 271\n",
            "Data loaded for 272\n",
            "Data loaded for 273\n",
            "Data loaded for 274\n",
            "Data loaded for 275\n",
            "Data loaded for 276\n",
            "Data loaded for 277\n",
            "Data loaded for 278\n",
            "Data loaded for 279\n",
            "Data loaded for 280\n",
            "Data loaded for 281\n",
            "Data loaded for 282\n",
            "Data loaded for 283\n",
            "Data loaded for 284\n",
            "Data loaded for 285\n",
            "Data loaded for 286\n",
            "Data loaded for 287\n",
            "Data loaded for 288\n",
            "Data loaded for 289\n",
            "Data loaded for 290\n",
            "Data loaded for 291\n",
            "Data loaded for 292\n",
            "Data loaded for 293\n",
            "Data loaded for 294\n",
            "Data loaded for 295\n",
            "Data loaded for 296\n",
            "Data loaded for 297\n",
            "Data loaded for 298\n",
            "Data loaded for 299\n",
            "Data loaded for 300\n",
            "Data loaded for 301\n",
            "Data loaded for 302\n",
            "Data loaded for 303\n",
            "Data loaded for 304\n",
            "Data loaded for 305\n",
            "Data loaded for 306\n",
            "Data loaded for 307\n",
            "Data loaded for 308\n",
            "Data loaded for 309\n",
            "Data loaded for 310\n",
            "Data loaded for 311\n",
            "Data loaded for 312\n",
            "Data loaded for 313\n",
            "Data loaded for 314\n",
            "Data loaded for 315\n",
            "Data loaded for 316\n",
            "Data loaded for 317\n",
            "Data loaded for 318\n",
            "Data loaded for 319\n",
            "Data loaded for 320\n",
            "Data loaded for 321\n",
            "Data loaded for 322\n",
            "Data loaded for 323\n",
            "Data loaded for 324\n",
            "Data loaded for 325\n",
            "Data loaded for 326\n",
            "Data loaded for 327\n",
            "Data loaded for 328\n",
            "Data loaded for 329\n",
            "Data loaded for 330\n",
            "Data loaded for 331\n",
            "Data loaded for 332\n",
            "Data loaded for 333\n",
            "Data loaded for 334\n",
            "Data loaded for 335\n",
            "Data loaded for 336\n",
            "Data loaded for 337\n",
            "Data loaded for 338\n",
            "Data loaded for 339\n",
            "Data loaded for 340\n",
            "Data loaded for 341\n",
            "Data loaded for 342\n",
            "Data loaded for 343\n",
            "Data loaded for 344\n",
            "Data loaded for 345\n",
            "Data loaded for 346\n",
            "Data loaded for 347\n",
            "Data loaded for 348\n",
            "Data loaded for 349\n",
            "Data loaded for 350\n",
            "Data loaded for 351\n",
            "Data loaded for 352\n",
            "Data loaded for 353\n",
            "Data loaded for 354\n",
            "Data loaded for 355\n",
            "Data loaded for 356\n",
            "Data loaded for 357\n",
            "Data loaded for 358\n",
            "Data loaded for 359\n",
            "Data loaded for 360\n",
            "Data loaded for 361\n",
            "Data loaded for 362\n",
            "Data loaded for 363\n",
            "Data loaded for 364\n",
            "Data loaded for 365\n",
            "Data loaded for 366\n",
            "Data loaded for 367\n",
            "Data loaded for 368\n",
            "Data loaded for 369\n",
            "Data loaded for 370\n",
            "Data loaded for 371\n",
            "Data loaded for 372\n",
            "Data loaded for 373\n",
            "Data loaded for 374\n",
            "Data loaded for 375\n",
            "Data loaded for 376\n",
            "Data loaded for 377\n",
            "Data loaded for 378\n",
            "Data loaded for 379\n",
            "Data loaded for 380\n",
            "Data loaded for 381\n",
            "Data loaded for 382\n",
            "Data loaded for 383\n",
            "Data loaded for 384\n",
            "Data loaded for 385\n",
            "Data loaded for 386\n",
            "Data loaded for 387\n",
            "Data loaded for 388\n",
            "Data loaded for 389\n",
            "Data loaded for 390\n",
            "Data loaded for 391\n",
            "Data loaded for 392\n",
            "Data loaded for 393\n",
            "Data loaded for 394\n",
            "Data loaded for 395\n",
            "Data loaded for 396\n",
            "Data loaded for 397\n",
            "Data loaded for 398\n",
            "Data loaded for 399\n",
            "Data loaded for 400\n",
            "Data loaded for 401\n",
            "Data loaded for 402\n",
            "Data loaded for 403\n",
            "Data loaded for 404\n",
            "Data loaded for 405\n",
            "Data loaded for 406\n",
            "Data loaded for 407\n",
            "Data loaded for 408\n",
            "Data loaded for 409\n",
            "Data loaded for 410\n",
            "Data loaded for 411\n",
            "Data loaded for 412\n",
            "Data loaded for 413\n",
            "Data loaded for 414\n",
            "Data loaded for 415\n",
            "Data loaded for 416\n",
            "Data loaded for 417\n",
            "Data loaded for 418\n",
            "Data loaded for 419\n",
            "Data loaded for 420\n",
            "Data loaded for 421\n",
            "Data loaded for 422\n",
            "Data loaded for 423\n",
            "Data loaded for 424\n",
            "Data loaded for 425\n",
            "Data loaded for 426\n",
            "Data loaded for 427\n",
            "Data loaded for 428\n",
            "Data loaded for 429\n",
            "Data loaded for 430\n",
            "Data loaded for 431\n",
            "Data loaded for 432\n",
            "Data loaded for 433\n",
            "Data loaded for 434\n",
            "Data loaded for 435\n",
            "Data loaded for 436\n",
            "Data loaded for 437\n",
            "Data loaded for 438\n",
            "Data loaded for 439\n",
            "Data loaded for 440\n",
            "Data loaded for 441\n",
            "Data loaded for 442\n",
            "Data loaded for 443\n",
            "Data loaded for 444\n",
            "Data loaded for 445\n",
            "Data loaded for 446\n",
            "Data loaded for 447\n",
            "Data loaded for 448\n",
            "Data loaded for 449\n",
            "Data loaded for 450\n",
            "Data loaded for 451\n",
            "Data loaded for 452\n",
            "Data loaded for 453\n",
            "Data loaded for 454\n",
            "Data loaded for 455\n",
            "Data loaded for 456\n",
            "Data loaded for 457\n",
            "Data loaded for 458\n",
            "Data loaded for 459\n",
            "Data loaded for 460\n",
            "Data loaded for 461\n",
            "Data loaded for 462\n",
            "Data loaded for 463\n",
            "Data loaded for 464\n",
            "Data loaded for 465\n",
            "Data loaded for 466\n",
            "Data loaded for 467\n",
            "Data loaded for 468\n",
            "Data loaded for 469\n",
            "Data loaded for 470\n",
            "Data loaded for 471\n",
            "Data loaded for 472\n",
            "Data loaded for 473\n",
            "Data loaded for 474\n",
            "Data loaded for 475\n",
            "Data loaded for 476\n",
            "Data loaded for 477\n",
            "Data loaded for 478\n",
            "Data loaded for 479\n",
            "Data loaded for 480\n",
            "Data loaded for 481\n",
            "Data loaded for 482\n",
            "Data loaded for 483\n",
            "Data loaded for 484\n",
            "Data loaded for 485\n",
            "Data loaded for 486\n",
            "Data loaded for 487\n",
            "Data loaded for 488\n",
            "Data loaded for 489\n",
            "Data loaded for 490\n",
            "Data loaded for 491\n",
            "Data loaded for 492\n",
            "Data loaded for 493\n",
            "Data loaded for 494\n",
            "Data loaded for 495\n",
            "Data loaded for 496\n",
            "Data loaded for 497\n",
            "Data loaded for 498\n",
            "Data loaded for 499\n",
            "Data loaded for 500\n",
            "Data loaded for 501\n",
            "Data loaded for 502\n",
            "Data loaded for 503\n",
            "Data loaded for 504\n",
            "Data loaded for 505\n",
            "Data loaded for 506\n",
            "Data loaded for 507\n",
            "Data loaded for 508\n",
            "Data loaded for 509\n",
            "Data loaded for 510\n",
            "Data loaded for 511\n",
            "Data loaded for 512\n",
            "Data loaded for 513\n",
            "Data loaded for 514\n",
            "Data loaded for 515\n",
            "Data loaded for 516\n",
            "Data loaded for 517\n",
            "Data loaded for 518\n",
            "Data loaded for 519\n",
            "Data loaded for 520\n",
            "Data loaded for 521\n",
            "Data loaded for 522\n",
            "Data loaded for 523\n",
            "Data loaded for 524\n",
            "Data loaded for 525\n",
            "Data loaded for 526\n",
            "Data loaded for 527\n",
            "Data loaded for 528\n",
            "Data loaded for 529\n",
            "Data loaded for 530\n",
            "Data loaded for 531\n",
            "Data loaded for 532\n",
            "Data loaded for 533\n",
            "Data loaded for 534\n",
            "Data loaded for 535\n",
            "Data loaded for 536\n",
            "Data loaded for 537\n",
            "Data loaded for 538\n",
            "Data loaded for 539\n",
            "Data loaded for 540\n",
            "Data loaded for 541\n",
            "Data loaded for 542\n",
            "Data loaded for 543\n",
            "Data loaded for 544\n",
            "Data loaded for 545\n",
            "Data loaded for 546\n",
            "Data loaded for 547\n",
            "Data loaded for 548\n",
            "Data loaded for 549\n",
            "Data loaded for 550\n",
            "Data loaded for 551\n",
            "Data loaded for 552\n",
            "Data loaded for 553\n",
            "Data loaded for 554\n",
            "Data loaded for 555\n",
            "Data loaded for 556\n",
            "Data loaded for 557\n",
            "Data loaded for 558\n",
            "Data loaded for 559\n",
            "Data loaded for 560\n",
            "Data loaded for 561\n",
            "Data loaded for 562\n",
            "Data loaded for 563\n",
            "Data loaded for 564\n",
            "Data loaded for 565\n",
            "Data loaded for 566\n",
            "Data loaded for 567\n",
            "Data loaded for 568\n",
            "Data loaded for 569\n",
            "Data loaded for 570\n",
            "Data loaded for 571\n",
            "Data loaded for 572\n",
            "Data loaded for 573\n",
            "Data loaded for 574\n",
            "Data loaded for 575\n",
            "Data loaded for 576\n",
            "Data loaded for 577\n",
            "Data loaded for 578\n",
            "Data loaded for 579\n",
            "Data loaded for 580\n",
            "Data loaded for 581\n",
            "Data loaded for 582\n",
            "Data loaded for 583\n",
            "Data loaded for 584\n",
            "Data loaded for 585\n",
            "Data loaded for 586\n",
            "Data loaded for 587\n",
            "Data loaded for 588\n",
            "Data loaded for 589\n",
            "Data loaded for 590\n",
            "Data loaded for 591\n",
            "Data loaded for 592\n",
            "Data loaded for 593\n",
            "Data loaded for 594\n",
            "Data loaded for 595\n",
            "Data loaded for 596\n",
            "Data loaded for 597\n",
            "Data loaded for 598\n",
            "Data loaded for 599\n",
            "Data loaded for 600\n",
            "Data loaded for 601\n",
            "Data loaded for 602\n",
            "Data loaded for 603\n",
            "Data loaded for 604\n",
            "Data loaded for 605\n",
            "Data loaded for 606\n",
            "Data loaded for 607\n",
            "Data loaded for 608\n",
            "Data loaded for 609\n",
            "Data loaded for 610\n",
            "Data loaded for 611\n",
            "Data loaded for 612\n",
            "Data loaded for 613\n",
            "Data loaded for 614\n",
            "Data loaded for 615\n",
            "Data loaded for 616\n",
            "Data loaded for 617\n",
            "Data loaded for 618\n",
            "Data loaded for 619\n",
            "Data loaded for 620\n",
            "Data loaded for 621\n",
            "Data loaded for 622\n",
            "Data loaded for 623\n",
            "Data loaded for 624\n",
            "Data loaded for 625\n",
            "Data loaded for 626\n",
            "Data loaded for 627\n",
            "Data loaded for 628\n",
            "Data loaded for 629\n",
            "Data loaded for 630\n",
            "Data loaded for 631\n",
            "Data loaded for 632\n",
            "Data loaded for 633\n",
            "Data loaded for 634\n",
            "Data loaded for 635\n",
            "Data loaded for 636\n",
            "Data loaded for 637\n",
            "Data loaded for 638\n",
            "Data loaded for 639\n",
            "Data loaded for 640\n",
            "Data loaded for 641\n",
            "Data loaded for 642\n",
            "Data loaded for 643\n",
            "Data loaded for 644\n",
            "Data loaded for 645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4VZHrMtEI1D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33899f74-6a5b-432a-da9e-606e48e5925b"
      },
      "source": [
        "augmented_train_images.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6458, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmurBfORu0_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_train_labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xayysDTRuzuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "# Convert the lists to numpy arrays for further processing and do scaling\n",
        "augmented_train_images = np.array(augmented_train_images)\n",
        "augmented_train_images = augmented_train_images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTxX334wvRwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(augmented_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0YdtR6svhhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the data to fit into the model\n",
        "x_train = augmented_train_images.reshape(len(augmented_train_images), 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdMQsmC1TUq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_mapping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-5gYZigQUGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e35e409-1c7b-4056-f932-0d8162e2676d"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6458, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuGtpmW1VaOR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8180c44-06ff-44e2-b3c5-05e2a5f27925"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6458,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ADdSDYEgCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "027a38a3-a149-46ce-a8c6-32747d7b7c2a"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(257, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fhndJliOG3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwDdU59DEoUm",
        "colab_type": "text"
      },
      "source": [
        "go to training part now"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWYGlki4yuJj",
        "colab_type": "text"
      },
      "source": [
        "Extra (maybe for later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KictYCwjFk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def resizeImages():\n",
        "    for filename in os.listdir(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/cropped/\"):\n",
        "        img = cv2.imread(os.path.join(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/cropped/\", filename), 0)\n",
        "        img = cv2.resize(img, (32, 32))\n",
        "        cv2.imwrite(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/resized/\" + filename, img)\n",
        "\n",
        "resizeImages()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6jIMg5EkL3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaYb9vlWPOZa",
        "colab_type": "text"
      },
      "source": [
        "Store Images in array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR1YJkxIMrUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_train_images = []\n",
        "for filename in os.listdir(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/resized/\"):\n",
        "  #count += 1\n",
        "  img = cv2.imread(os.path.join(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/train/resized/\", filename), 0)\n",
        "  img = cv2.resize(img, (28, 28))\n",
        "  if img is not None:\n",
        "    temp_train_images.append(img)\n",
        "\n",
        "train_images = np.array(temp_train_images)\n",
        "train_images = train_images / 255.0\n",
        "x_train = train_images.reshape(len(train_images), 28, 28, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vchaUW1XDodD",
        "colab": {}
      },
      "source": [
        "run_detector(detector, downloaded_image_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsxP7vJAROKm",
        "colab_type": "text"
      },
      "source": [
        "Training Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Tks7tEV0l7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install keras-tuner"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnqppJInRP4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]),\n",
        "        activation='relu',\n",
        "        input_shape=(28, 28, 1)\n",
        "    ))\n",
        "    model.add(keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(\n",
        "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(keras.layers.Dense(8, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    directory='output',\n",
        "    project_name='models'\n",
        ")\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=3, validation_split=0.1)\n",
        "\n",
        "model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDlK6rAyFMvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=100 , epochs=50, validation_split=0.1, initial_epoch=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b_nq_TQF_xC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.argmax(model.predict(x_test), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCrM4ajHGEn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMj_DwvHGisB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYOr0xxlGzQR",
        "colab_type": "text"
      },
      "source": [
        "append to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7-w9sXAGyk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pd.DataFrame(y_pred)\n",
        "sub_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/new_test.csv\")\n",
        "datasets = pd.concat([sub_df[['Image','parent_image']],pred], axis=1)\n",
        "datasets.columns = ['Image','parent_image','target']\n",
        "datasets.target = datasets.target.astype(int)\n",
        "datasets.to_csv('/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/my_submission1.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hlf_2UaPkCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/my_submission1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6V8V_ZRSCTd",
        "colab_type": "text"
      },
      "source": [
        "Find mode of parent_image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKbGRRFZPcRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df = datasets.drop(['Image'], axis=1)\n",
        "new_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV2zlnPhIAOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import mode\n",
        "modes = new_df.groupby('parent_image')['target'].apply(lambda x: mode(x)[0][0]).reset_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0r6h-RzNmbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modes.columns = ['Image','target']\n",
        "modes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikNhNxK5R778",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUOA5MbTSZ4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df = test_df.merge(modes, on=\"Image\", how = 'inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbbnuuyHTbJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df[\"target\"] = pd.to_numeric(final_df[\"target\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3BkIwXDJYnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRL5INm_S4VE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_mapping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQf2NfmPTyOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_mapper = dict((v,k) for k,v in y_mapping.items())\n",
        "target_mapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np7SZYqlTE6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final = final_df.replace({\"target\": target_mapper})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB8wWkqRUBJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBDdkephUFDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_final.to_csv('/content/drive/My Drive/Colab Notebooks/data/DanceForms_HE/my_submission_full.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rubdr2JXfsa1",
        "colab": {}
      },
      "source": [
        "image_urls = [\n",
        "  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\n",
        "  \"https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg\",\n",
        "  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n",
        "  \"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg\",\n",
        "  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg\n",
        "  \"https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg\",\n",
        "  ]\n",
        "\n",
        "def detect_img(image_url):\n",
        "  start_time = time.time()\n",
        "  image_path = download_and_resize_image(image_url, 640, 480)\n",
        "  run_detector(detector, image_path)\n",
        "  end_time = time.time()\n",
        "  print(\"Inference time:\",start_time-end_time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "otPnrxMKIrj5",
        "colab": {}
      },
      "source": [
        "detect_img(image_urls[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H5F7DkD5NtOx",
        "colab": {}
      },
      "source": [
        "detect_img(image_urls[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DZ18R7dWNyoU",
        "colab": {}
      },
      "source": [
        "detect_img(image_urls[2])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}